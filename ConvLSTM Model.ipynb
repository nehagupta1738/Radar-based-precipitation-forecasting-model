{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UwqnGiAofHup"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "akuBxb_AfLM8"
      },
      "outputs": [],
      "source": [
        "# Set the input and output shapes\n",
        "INPUT_SHAPE = (128, 128, 4)  # Input shape of the model\n",
        "OUTPUT_SHAPE = (128, 128, 1)  # Output shape of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zw_X597zxEAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d570785-7632-48a5-ea0f-03fb3d9db1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_max = '/content/drive/MyDrive/example1/min_max_scale_new.npy'\n",
        "min, max = np.load(min_max, encoding='bytes')\n",
        "print(min, max)"
      ],
      "metadata": {
        "id": "utKNwsA4DYRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3658b4-fdf7-439a-8f66-a495458730ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-236.2857142857143 295.5714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O5jOpSEHfYDg"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "def load_data(file_path):\n",
        "    data = np.load(file_path)\n",
        "    return data\n",
        "\n",
        "def preprocess_data(file_list):\n",
        "    # data = []\n",
        "    # labels = []\n",
        "    loaded_data = []\n",
        "    for file_name in file_list:\n",
        "        file_path = '/content/drive/MyDrive/example1/' + file_name\n",
        "        loaded_data.append(load_data(file_path))\n",
        "    return np.array(loaded_data)\n",
        "\n",
        "\n",
        "def generate_data(data,min_train,max_train):\n",
        "    # data shape=(n_samples, row, col, timesteps)\n",
        "    n_samples=data.shape[0]\n",
        "    time_step=data.shape[3]\n",
        "    row=128\n",
        "    col=128\n",
        "\n",
        "    # replace the pixel of \"no echo (-127)\" as 0\n",
        "    data[data<=-127]=0\n",
        "\n",
        "    # for training dataset (t-30,t-20,t-10,t,1+10)\n",
        "    n_frames=4\n",
        "    movie_in=np.zeros((n_samples,row,col,n_frames))\n",
        "    movie_out=np.zeros((n_samples,row,col,1))\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_frames):\n",
        "            m_in=(255.*((data[i,::,::,j]+10.)/70.))+0.5\n",
        "            movie_in[i,::,::,j]=m_in\n",
        "        m_out=(255.*((data[i,::,::,-1]+10.)/70.))+0.5\n",
        "        movie_out[i,::,::,0]=m_out\n",
        "\n",
        "    # Min-max scaling\n",
        "    movie_in=(movie_in-min_train)/(max_train-min_train)\n",
        "    movie_out=(movie_out-min_train)/(max_train-min_train)\n",
        "\n",
        "    return movie_in, movie_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2OuZxTXtfla-"
      },
      "outputs": [],
      "source": [
        "# Load the training and testing data\n",
        "train_file_list = np.loadtxt('/content/drive/MyDrive/example1/radar_events_train.txt', dtype=str)\n",
        "test_file_list = np.loadtxt('/content/drive/MyDrive/example1/radar_events_test.txt', dtype=str)\n",
        "\n",
        "data_train = preprocess_data(train_file_list)\n",
        "data_test = preprocess_data(test_file_list)\n",
        "\n",
        "\n",
        "x_train, y_train = generate_data(data_train, min, max)\n",
        "x_test, y_test = generate_data(data_test, min, max)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.moveaxis(x_train,3,1)\n",
        "x_test = np.moveaxis(x_test,3,1)"
      ],
      "metadata": {
        "id": "fHtPwcohZMJG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(y_train.shape[0],1,128,128,1)\n",
        "y_test = y_test.reshape(y_test.shape[0],1,128,128,1)\n",
        "x_train = x_train.reshape(x_train.shape[0],4,128,128,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],4,128,128,1)"
      ],
      "metadata": {
        "id": "D3OkoUGefcjD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "_2zyI1TJX-u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46368a4c-9793-4d2a-fd6f-d501eb99f6e9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1845, 4, 128, 128, 1) (1845, 1, 128, 128, 1)\n",
            "(1247, 4, 128, 128, 1) (1247, 1, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras"
      ],
      "metadata": {
        "id": "0wPbAbC_uQSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d5d629-a896-479f-aa9b-28f58e650e9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM"
      ],
      "metadata": {
        "id": "XcADYIzyacZY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers import LayerNormalization, Reshape, Lambda\n",
        "import keras.backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=64,\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     kernel_initializer='HeNormal',\n",
        "                     input_shape=(None, 128, 128, 1),\n",
        "                     return_sequences=True))\n",
        "model.add(LayerNormalization())\n",
        "model.add(ConvLSTM2D(filters=64,\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     kernel_initializer='HeNormal',\n",
        "                     return_sequences=True))\n",
        "model.add(LayerNormalization())\n",
        "model.add(ConvLSTM2D(filters=64,\n",
        "                     kernel_size=(3, 3),\n",
        "                     padding='same',\n",
        "                     kernel_initializer='HeNormal',\n",
        "                     return_sequences=True))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Conv3D(filters=1,\n",
        "                 kernel_size=(3, 3, 3),\n",
        "                 padding='same',\n",
        "                 activation='linear',\n",
        "                 data_format='channels_last'))\n",
        "\n",
        "# Define a Lambda layer for element-wise multiplication along the second axis\n",
        "multiply_layer = Lambda(lambda x: K.prod(x, axis=1, keepdims=True))\n",
        "model.add(multiply_layer)\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.build((None, 4, 128, 128, 1))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "4EZEjftYgZr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1xdnp7zgfc_"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=8, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "loss, metric = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(loss, metric)"
      ],
      "metadata": {
        "id": "7IvgCccixDjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=y_test.reshape(1247,128,128)\n",
        "predictions=predictions.reshape(1247,128,128)"
      ],
      "metadata": {
        "id": "C77FYFpdpxnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aphA6l-gixS"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save('ConvLSTM.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}